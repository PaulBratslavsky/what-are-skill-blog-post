DeepLearning.AI

Transcript Skills are folders of instructions that package repeated workflows, specialized knowledge, or new capabilities for your agent. If you find yourself typing the same prompt across conversations, you should consider transforming that into a skill. Let's explore how to do that using Claude AI. So before we talk a little bit more about skills and dive into what a skill looks like and how it works, let's walk through a scenario to showcase why skills are so useful. Right here, I've got some campaign data in a CSV that I'd like to analyze the performance of. So just to show you what this looks like, I've got a date, a campaign name, impressions, clicks, conversions. You can imagine here that we're going to take in some marketing data use Claude to analyze this information. So in my first prompt, I'm attaching this data, explaining what the input data looks like, asking to check for quality, funnel analysis, and some useful metrics around what I expect for click-through rates and conversion rates. At the bottom, I've got an output format that I'm requesting for this particular piece of data. Now you can imagine it would be valuable to not have to include this prompt every time and to have that packaged up. As we take a look at what we're seeing in our campaign data, Claude is going to read this CSV. It's then going to perform the Data Quality Check and Funnel Analysis and give us back our campaign performance analysis. Here it's going to show the Total Records, any Missing Data, and any Anomalies in the data that exist. If we take a look a little bit further, we'll see our Funnel Analysis versus the benchmark data that we were looking for before. We can see here, some things that are working better, some things that are not working as well. We're getting a lot of useful data back that we can take action around, change our marketing campaigns and move forward. We've got a nice interpretation of what Claude is telling us, what's working, what's not working. And now we're going to go ahead and ask for additional computations of certain efficiency metrics for marketing. These include return on our ad spend, cost per acquisition, and net profit and so on. We're also going to ask for an output format in a certain fashion. We'll see the results from this efficiency analysis, we'll see what's working, again, what's not working and some interpretations. we'll see our portfolio performance and our total net profit. Looks like we're making money here, but there's still much more that I'm sure we can do. The next step that we're going to do here is to take in an additional piece of data, our budget reallocation rules. The idea here is that we have extra money to play around with and think about allocating towards other marketing channels. You can imagine this file has quite a bit of data around the rules for allocating, what we're trying to figure out and how best to decide where to increase our budget. This could also lead to maintaining a budget or decreasing a budget based on this framework that we have here. Again, this is a lot of data that is specific to our particular use case. Claude knows how to handle particular decisions and analyze marketing metrics, but here we're specifying exactly the way that we want to do things. This requires me bringing in external documentation, finding the right people, and even if I'm not the most knowledgeable about this, hoping that I get it right. We're going to go ahead and see these allocation rules, our recommendations. We can see what's passing, what's not passing, and a proposed reallocation here. Freeing up some budget, analyzing what's working and where to allocate additional budget towards. What we've seen here is a step-by-step process that requires us as the user to put in the necessary documentation and have the necessary pre-existing knowledge. Not only that, but everything that I'm putting in here is immediately getting added to the context window. What happens if I want to ask something different? What happens if I want to have a different kind of conversation? This information here is not always necessary for everything I'm going to do. What we're going to take a look at here is how we can take this information and package it into a skill. a standalone asset, a folder really, that contains instructions for how to go about performing the campaign analysis while also being intentional about what information goes into the context window and what information doesn't. As we've seen, this is a weekly campaign performance analysis. So this isn't something that I want to have to repeat on my own every single week with this particular prompt by copying and pasting. This is going to be much nicer to have pre-packaged that I can use myself, share with members of the team, and edit as necessary. So with that, let's take a look at what a SKILL.md file is. This file needs to be named SKILL.md in markdown format. And this is going to be the underlying set of instructions to perform the task that we saw. In this Markdown file, I have very similar information to what I included in the previous prompt. I have my input requirements, a data quality check, funnel analysis with the metrics that we were working at before, and historical benchmarks. I have that same Efficiency Analysis as well as the Output Format that I expect. Finally, I have a note here on Budget Reallocation that references a different file only when the user asks about Budget Reallocation. So we talked a little bit about how this can be much more efficient with context. This is one example where I'm only going to be reading and using this file if a user asks about that particular piece of information. In order to get this skill to work as expected, there's one more piece of data that I need to add to the beginning here. This data is in a data format called YAML, and here's what it looks like. Every skill that you make across the entire standard requires a name as well as a description. The name of the skill is going to be important for referencing when to use it and in the UI that we're working with if it's being used. And the description is important so that the model that we're working with can understand when to use this particular skill. When you make a skill, the name and description are required. So we've got our SKILL.md file, and the second file I want to show you is just this budget_reallocation_rules.md file, which is very similar to the other prompt that we saw. When you make a skill, your skill can reference other files as long as they're all in the same parent folder. These budget reallocation rules are exactly what I put in that previous conversation with Claude AI. So what we're doing here is we're moving away from putting in instructions directly in our conversation, and instead putting it into a folder. Now that I've got this SKILL file, as well as any external files, What I'm going to do here is make a new folder. And I'll name that folder the name of the skill, analyzing-marketing-campaign. There are some high-level rules around naming skills. Stick with lowercase letters, use dashes between words, and don't use reserved keywords like Claude or Anthropic. Now that I've created this folder for the skill that I'm making, I'm going to go ahead and make another folder called references. When we look at the open standard for skills, we're going to see that this actually is a specific name that we use when there are external references that the skill uses. And inside of our SKILL.md, we linked to references/budget_reallocation_rules. So I'll go ahead and put that file in this folder. I'll put the folder inside of our marketing campaign. And then I'll put the SKILL.md at the top level of this folder. If we take a quick look at what's inside, we should see our SKILL.md as well as our references folder that contains that additional budget allocation file. Now I'm going to go ahead and create a zip file from this folder and I'm going to go ahead and upload that to Claude AI. Once I upload that skill, I should be able to start using it in future conversations. I'm going to head over to my Settings right over here. And I'm going to go to Capabilities. As I navigate to the bottom of Capabilities, we're going to see this section on Skills. There are some example ones that we'll talk a little bit about later. But right now, I want to add my own. So I'm going to go ahead and add, and I'm going to upload the skill in a zip file that I created. I'm going to go ahead and drag and drop that zip file and give that a second to upload. Once that's done, we can see the name of our skill as well as that description. Now that we've uploaded our skill, let's go see this in action. I'm going to start with a new chat. I'm going to go ahead and ask Claude a similar prompt to what I had before. And I'm going to go ahead now and attach the same CSV that I was working with before. If this works as expected, we should start to see Claude pick up the skill for our weekly marketing campaign. Claude should then perform the tasks required in that skill and the need for us to have all that prompt back and forth is no longer there. So let's go ahead and see what Claude can do here. We'll see here it's going to read this skill file to ensure it's following the right instructions. The name of our skill as well as the description is what is allowing Claude to pick this up. Since we're asking about reallocating the budget, it's going to go ahead and read that additional file that we uploaded to our skill. We'll then go ahead and analyze the data. If you want to see the code that Claude is running and executing here, we can always open this up and take a look at what's happening behind the scenes. What we're going to see here is something very similar to what we saw before. we're going to analyze channels that may have additional challenges, in this case TikTok. We may see things that are working as well as recommended reallocations. But in this case, we didn't have to add all the prompting ourselves. This skill can be shared across many different platforms. And since skills are an open standard, this is supported in other coding environments like Codex, Gemini CLI, and much more. So not only have we created a way to take this data and package it up into a centralized place, we're being more efficient with the context window and the portability here is extremely valuable. Now, let's go ahead and create a report with the data that we found. We're going to go ahead and create an Excel report with the following pieces of information as well as a color coding that we're recommending. Under the hood, the ability to create spreadsheets and execute necessary code to do so, actually lives in a skill that comes built-in to Claude. So we're actually going to see the underlying skill being used, code being run to create this Excel file, and then finally the output based on the requirements that we specified. We've got our spreadsheet now. Here we can see, we've got an Executive Summary, Funnel Analysis, Efficiency Analysis. And we can go and open this in Google Drive or download this spreadsheet. Through the use of our skill to analyze data and give us what we need, as well as built-in skills to create spreadsheets, we can transform data from CSVs into meaningful, actionable insights in many different kinds of file formats. Next, we'll explore in a little bit more depth what a skill looks like, how it works, and where it fits into the entire AI ecosystem.

DeepLearning.AI

Transcript In the previous lesson, we saw how to create skills in Claude and move from prompts with data to package skills that we can use across many different conversations. Now let's dive deeper and talk about what skills are and the open standard that powers them. Similar to the model context protocol, skills themselves are an open standard that can be used across many different AI applications. While skills were something originally created at Anthropic. Skills themselves are now an open standard with a specific specification that is used across many different platforms, including Codex, Gemini CLI, Claude Code, Open Code, and much more. With that in mind, let's talk a little bit about how this works. When we build AI applications, in order to use particular skills, we need to make use of some kind of file system when using tools like Claude AI or Claude Desktop. In that file system, we load folders that contain a SKILL.md file and subfolders or files that can be referenced. Here we can see exactly what we did previously. At the same time, skills themselves cannot only include other markdown documents, but scripts that can be executed. For example, we have a skill for working with PDF documents. we need to convert PDFs to images, extract info from form fields, and even fill PDF forms with annotations. This requires code to be executed. But that code that needs to be executed can be referenced from the SKILL.md file. So as we start to explore our own custom skills and built-in skills, it's important to note that skills are not just text files that reference other text files, but text files that can reference scripts, what they do, and when they need to be executed. Skills can also include icons, images, and other assets as we start to think about ways of creating custom styles and brands. Where skills really shine are places where Claude might not know exactly how you or your company operates. You can imagine designing newsletters, creating brand guides, things that Claude has a general idea on, but not the exact way that your company or your team does it. To give some more idea of why we bring agent skills into the mix when we're building our own agents. The way that we used to think about building agents centered around agents with a single purpose. Coding, research, finance, marketing, and much more. These domain-specific agents had a particular set of tools, the context that it needed to perform the task necessary. But as we started to build more of these single-purpose agents, we started to realize that under the hood, all that they really need is a simple scaffolding. Underlying tools like bash and a filesystem, to find, edit, modify, execute, and perform whatever tasks are necessary. These simpler agents are easier to evaluate, understand, and scale. But what these agents lacked was the underlying context and domain expertise to do the job reliably. That context can be provided through skills, through the model context protocol, but that domain expertise is really where skills shine as well. We want finance agents to perform financial analysis in a particular fashion. We want research agents to have the domain expertise necessary to research the way that we want. to be able to port that across many different ecosystems and agents, and that's why we have agent skills. These skills provide us the procedural knowledge and the user-specific context that they can load on demand. In addition to domain expertise, skills can also provide a repeatable workflow. In a non-deterministic system, where we don't always know exactly what the output of the model is going to be, it can be difficult to find repeatable ways of producing the same output. What skills allow us to do is provide a repeatable workflow. with very articulate steps or instructions that allow the agent to perform a task that we can start to predict with more accuracy. Skills also introduce the idea of new capabilities, things that an agent does not know how to do out of the box or even data that Claude has no idea how to operate on. When we bring in these new capabilities, we unleash an entire ecosystem and new functionality for our agents with minimal additional context. As we think about domain expertise, we want to lean on things that Claude might not know how to do or knows how to do but not for your particular domain. Claude can perform data analysis. Claude can perform legal review. But how does it do it the way that you or your team or company want it to be done? We previously saw the ability to perform weekly marketing campaign reviews, and we want that to be predictable across many different individuals and teams. As we start to think about some of these new capabilities, things like generating presentations, Excel spreadsheets, PDF reports, executing scripts when necessary to perform those actions, that here is where agent skills can shine. What we saw previously, without skills, was the idea of describing our instructions, trying to predict workflows and bundling all of the necessary files in context at one time. We talked a little bit about the portability of skills. And while we've seen skills so far in Claude AI, skills can be used in the exact same format, not only across Claude Code, the Agent SDK and the API, but since Agent Skills are an open standard, you can use this across a growing number of agent products. You can create skills in one environment and use them and share them and scale them across many different environments. When we say that skills are composable, this is something that we've seen already. We can take custom skills like analyzing our marketing campaign and we can combine that with built-in skills like creating PowerPoint presentations, PDFs, or Excel spreadsheets. Not only can we use multiple skills together, but we can combine them to build complex and predictable workflows. We can reference the skills necessary, the steps necessary, and start to create predictable outputs in a non-deterministic system. Under the hood, skills can contain quite a bit of information. We saw examples with additional markdown files and even examples with scripts that can be executed. You can have hundreds of skills across your system, and what we're going to see quite a bit more is that to protect the context window, skills are progressively disclosed. The idea of Progressive Disclosure is to only load the data necessary and avoid polluting the context. We like to think of the context window as a public good. The more data that we add to the context window, the more tokens we consume, the faster our context window fills up, and the likelihood of context degradation or incorrect responses potentially increases. In order to avoid polluting the context window with data that we might not need, skills introduce the idea of Progressive Disclosure. When skills are loaded from the file system, the only data that gets added to the context window is the name and description of the skill. This is essential so that Claude or any other system knows what the skill is and how to trigger it. Once that skill is triggered, the underlying SKILL.md is loaded. This is the next phase of loading data into context. And depending on what is required, if there are additional files or scripts that need to be loaded and executed, those will be loaded progressively. These additional resources can be loaded as needed, and if there are scripts that need to be loaded, those scripts are loaded and executed separately from the context window to avoid polluting with additional tokens that are not necessary. By using tools like bash and a file system, Claude can load only the information that's necessary, execute only scripts and reading of files that is necessary, and intentionally only add what is necessary to the context window. In the next lesson, we'll continue talking about skills and particularly how they're used alongside other technologies like the model context protocol, sub-agents, underlying tools, and much more.

DeepLearning.AI

Transcript You can combine skills with tools, MCP, and subagents to create powerful agentic workflows. Let's go through each component, see how they work together and learn when to use what. I'll see you there. In this lesson, we're going to explore how skills fit in to the agent ecosystem. With so many different technologies, like MCP, skills, tools, and subagents, let's make sure we understand how they all work together. In your existing applications, we can bring in MCP servers for the context that we need. leverage subagents for their own main thread and parallelization and bring in skills for those repeatable workflows. Let's see this in a little more depth. When we compare skills with the model context protocol, we want to think a lot about working with external data systems and bringing in the tools and resources that we need. The model context protocol connects our agent or AI applications with external systems and data. That could be an external database, data from Google Drive. using a various array of systems, but anytime that you need external data and context that the model doesn't know about, the model context protocol is extremely helpful. The skills that you have can leverage those underlying tools and data from the model context protocol to teach your agent what to do with that data. Think of the model context protocol as bringing in all of the underlying tooling that we need, and the skill as the set of instructions to put those tools together to build particular workflows that are repeatable and produce the kind of data that you want. As we think about leveraging external data to compute metrics and research and calculate data, all of those underlying tools can be provided externally through the model context protocol. When we think a little bit about skills versus tools, I like to draw the analogy of tools as a little bit more lower level. You can imagine that you have tools like a hammer and a saw and some nails. And you have a skill, like how to build a bookshelf. The tools themselves are underlying ways of accessing systems and providing agents with the capabilities they need to accomplish a task. In fact, tools are used under the hood to power the ability to generate skills, to read skills, and even to produce a Filesystem for executing code and loading these skills. Skills extend the capabilities with specialized knowledge, bringing in additional files and scripts that need to be executed, but the ability to execute those underlying scripts and load those files and folders is provided by tools. There are tools that are built in to certain agentic ecosystems, there are tools that we can write on our own, and tools that we can load through the model context protocol. Tool definitions always live in the context window, whereas skills are progressively loaded when necessary. When we think about how these work together, skills allow us to create predictable workflows, and those skills can bring in scripts that can be executed kind of like a tool on demand. If there is a tool that we do not need in every single conversation we can use that only when needed through skills and progressive disclosure. When we think about how subagents fit into the mix, let's first define what we think of as a subagent. We have a main agent that can spawn or create subagents that can report back to the parent agent. These subagents can be created through ecosystems like Claude Code or the agent SDK, or we can also make our own. When we think of the value that subagents provide, we think a lot about having an isolated context with fine-grained permissions, as well as executing tasks in parallel. When we think about what these Subagents can access, we have limited tool permissions, and we also can specify what skills each subagent can access. So while the main agent can serve as an orchestrator and can leverage whatever Skills necessary, Subagents can do the same type of idea with making use of particular skills. Subagents work quite nicely with skills where we can have a particular subagent like a Code Reviewer, whose sole task is to analyze and review a code base and leverages skills which specify exactly how you, your team, or your company might perform a code review. When we put this all together, we can provide an analogy of a Customer Insight Analyzer. Let's think about how this all works together. We have a main agent that is given a set of tools. Those tools could be provided from MCP servers we can bring in the data, the resources, the tools necessary to perform the tasks needed. For dispatching subagents to analyze customers, we might analyze interviews from customers or surveys from customers, do those in isolation and parallelize them to get data back even faster. When we think about how to actually analyze insights from customers, how to categorize feedback, summarize findings, how to analyze interviews and surveys, and how to make sure we do those in a predictable fashion with the right tools loaded at the right time, that's where skills come into play. We bring in data externally. We leverage subagents if we need to parallelize and execute in a separate thread and context window, and we bring in skills to consume all of this information in a predictable, repeatable, and portable fashion. To summarize this, there are many different pieces in the AI ecosystem when we think about building AI applications. Fundamentally, we have prompts, the underlying most atomic unit in a conversation. Prompts are the underlying tool for us to communicate with models. But prompts themselves don't scale very well across teams and companies. To bundle these underlying prompts and conversations and code and assets, we can leverage skills. Subagents that we have tasks delegated to can make use of skills. Those subagents can then consume tools necessary from a main agent that are defined through the model context protocol. As we think about what these particular features aim to solve, we want to be really intentional about how we're loading this information and what this is best used for. When we think about the context window as a public good, we want to be intentional about when subagents can help us minimize what goes in the main context window and how MCP can load the data necessary and skills can load it progressively. When we talk a little bit about the persistence and how we can think about drawing things into a longer-term memory. With subagents, we can persist across many different sessions from the subagent and the parent agent. With skills, we can persist across conversations that we have with the user and the AI application. So as we think about where each of these steps are used, we want to use skills for procedural, predictable workflows and subagents for full agentic logic only when necessary for specialized tasks. In the next lesson, we'll take a look at some of the pre-built skills that come with Claude. We'll take a look at the repository for these skills, dive deep into some of the SKILL.md files and talk about a very useful skill called the skill creator, so that we don't have to manually create all of our skills from scratch.

DeepLearning.AI

Transcript In the first lesson, Claude AI used the Excel skill to create spreadsheets displaying the marketing results. The Excel skill is one of Anthropic's pre-built skills, which also include a PowerPoint, Word, and PDF skill, as well as a skill creation skill. Let's take a look at those. Now that we've seen how skills fit in the entire AI ecosystem, let's take a look at some of the pre-built skills that you can use out of the box with Claude AI and Claude Desktop, and that you can install yourself with tools like Claude Code. Inside of this repository that lives at github.com/anthropic/skills. Let's take a look at the skills folder and see which built-in ones that we have. All of these are ready for production usage. And we actually saw in a previous lesson the use case of this Excel skill. It's important to note that this list of skills, while created at Anthropic, is actually bucketed into two different sections. The skills for Microsoft Docs, PDFs, Power Points, and Excel are known as document skills. These are built in and always used in tools like Claude AI. The remainder of these skills are examples that we've created that you can toggle on and off in Claude, but by default with the exception of skill-creator are toggled off. Let's first start by analyzing the PowerPoint skill. We can see just like other structures that we have a SKILL.md file as well as other files and folders to reference. Inside of this SKILL.md, we have that same YAML Frontmatter that includes the name and the description. What you're seeing here is how GitHub is rendering this markdown file, but the underlying code looks very similar to what we've made before. You can view it this way if you're familiar with markdown files. I'll switch back to the preview because it looks a little bit nicer. When we take a look at how this skill works and what it does, We've got an overview. The users may ask to create, edit, analyze contents of a PowerPoint file. Here's what it looks like, here's how you read it. And if there are particular tasks that need to be done, there are underlying scripts to go ahead and execute. Remember, these are not executed right out of the box. These are only loaded and executed when necessary. There's quite a bit that we can do with PowerPoint presentations, colors, typography, as you can imagine, this is how we can start to make things that look nicer and look more like real-world presentations out of the box. There are design principles that we have, requirements that are necessary, and color palette selections that we can have Claude pick from when the user does not specify them. This SKILL.md is quite long, as there is quite a bit that we can do with PowerPoint presentations. But what we're going to see later in this lesson is how to actually use this skill to take existing data and turn it into a beautiful looking presentation. The next skill I want to show you is a little bit of a meta idea here, and that's called the skill-creator. And the skill creator is a skill that serves the purpose of programmatically creating skills for you. Instead of having to do things from scratch and create the necessary files and folder structure, the skill creator can do that for you. Let's take a look at the SKILL.md file and see what's happening here. Similar to our other skills, we have a name and a description. And I'm actually going to take a look at the underlying code here, since it's a little bit easier to follow. We specify in this SKILL.md file what skill is, what it provides, and then we include some of the best practices associated with skills. We're going to dive into those best practices in the next lesson. But you can imagine when Claude is programmatically creating skills for you, we want to leverage some of these best practices. When we take a look at the skill creation process, we're extremely explicit with the steps that we have here. Since we want to use this skill to create a predictable workflow, we want to be extremely explicit with what the steps are, how to follow them, and what to skip only if some reason exists. We start with concrete examples, we plan reusable skill contents, and here you can start to see examples that are very helpful for Claude to pattern match when there's a skill you'd like to create. When we start initializing the skill, here we're running underlying Python scripts to perform the task necessary. Let's take a look at what those scripts do. Inside of the scripts folder, I have three Python files here. A script to initialize the skill and provide the underlying text, a Python file to package that skill, and then a script to validate that skill. Let's take a look at what this underlying code does to initialize a skill. We take an existing template that we have with some YAML Frontmatter and some placeholders and to-dos, and we fill that in based on the data that is coming in. This underlying script allows us to create the necessary text files when making our skills. Once we've generated the necessary files, we can package that up. Here you can see we're bringing in the necessary modules to zip our skill necessary and make sure that we're doing this in the right folder and file structure. Finally, we have one last script to perform a validation of our skill. make sure that a SKILL.md exists, validate some of the YAML Frontmatter, and make sure that what we put inside of our folder and files is correct. We're going to be leveraging this skill-creator skill to take existing content that we have and package it up into a reusable and modular script. Now let's go ahead and shift gears back to Claude and see how to put together built-in skills, our own skills, and a predictable workflow with an MCP server. Back in Claude, let's go and take a look and make sure that we have the correct skills enabled and where those live. Back in settings, inside of capabilities. We saw previously, we can create skills in this section. What I want to show you are the example skills that we have and this should look pretty familiar. This is what we saw on GitHub. By default, these skills are turned off. If we want to toggle them on, we can absolutely do so. The skill that is toggled on by default is the skill-creator that we just saw. It's important to note that while the skill-creator is extremely effective at creating underlying skills and structure necessary, we still have to be intentional about the prompt that we provide and the data that goes in to the skill that we're going to make. What we're going to do now is put all of these ideas around skills, MCP, and prompting together. First, we're going to modify our previous skill that we created for analyzing campaigns. to not use a CSV for data, but instead BigQuery. If you're not familiar, BigQuery is a data store powered by Google, and in order to bring in the necessary tooling and context to work with BigQuery, we're going to connect an MCP server. So we're going to use the skill-creator skill to modify our previous marketing analyzing skill to use BigQuery. We're then going to use skill-creator to create another skill. This will be for the purpose of brand guidelines. We'll include a file that specifies the guidelines as well as logos, and we'll build for ourselves another skill to perform that task. Finally, we'll take our two skills that we used to extract and analyze data and to leverage brand guidelines and combine them with a built-in skill for creating PowerPoint presentations to create a workflow that makes use of prompting, skills, and the model context protocol. Before we jump in, you might be wondering where the Excel and PowerPoint and other document skills that we saw before live. These are built in to Claude AI. and are not things that can be toggled on and off. So with that in mind, let's start this workflow. Before we modify our analyzing marketing campaign skill to use BigQuery, Let's also make a note that we're using Claude desktop here to connect to a local MCP server to leverage BigQuery. So let's take a look at how that BigQuery server is configured. I'm going to head over to Settings, Developer And here, we can take a look at the underlying command and arguments and environment variables for the particular project and where my credentials live. For this example, we don't have to use BigQuery, you can use a database, some external data store, but we just want to showcase what it looks like with skills and MCP servers working together. And if you're interested in seeing that underlying config file, here's what it looks like. In this config file, we specify the servers we want to connect to and the underlying commands to run when Claude Desktop starts. With that in mind, let's go ahead and modify our previous skill to now use BigQuery instead of CSVs for data access. To make sure this is working correctly, let's first ask Claude to list the tables in BigQuery that exist. This is going to make use of the MCP server that we have. We're going to allow this and we should get back the list of tables. In this case, we only have one. So here we can see there's a data set called marketing that contains a single table. Now we're going to ask Claude to show me the schema of the table. Hopefully Claude can pick up that small spelling mistake and we should be in business. Here we're specifying what the table looks like. And this looks great. And we're going to make use of this schema when we go ahead and update our analyzing-marketing-campaign skill. What we're going to do now is ask Claude to update our analyzing-marketing-campaign skill so that instead of a CSV upload, we pull from BigQuery. We specify the data from the BigQuery table, specifically the schema that we just saw above. Since we're all in one single conversation, Claude should have no problem taking a look at what the schema is. We're specifying some requirements for this, and just like in our existing skill, we want to make sure that the reference to our budget reallocation rules does not get modified. Like we spoke about earlier, the skill creator skill is extremely helpful and efficient, but we still need to give the context necessary. Notice here, the first thing it's going to do is analyze the necessary skill structure and use our skill creator skill to modify the existing skill and follow best practices. We're going to go ahead now and create the updated skill with a new SKILL.md file. Here we can start to see something that feels similar to our previous skill. But instead adding BigQuery instead of CSV uploads. Under the hood, we're using the file system and bash tools to create the necessary file and folder structure for us. What we can see here is instead of using a CSV, we're using BigQuery and we're following the best practice of using MCP servers with skills where we specify the server and the name of the tool. The skill-creator is following best practices to take our existing skill and modify it. So as we instructed skill-creator, when we specified our required input. We're seeing this in practice right now. It's best practice not to use an ambiguous date range or the entire range, so we ask the user to clarify, and when we show an example of querying, we're specifying a date range. So some of the tools and requirements that we put in are being directly applied when we update this skill. So our skill looks like it's in great shape. In order to make sure this is saved to subsequent conversations, let's go ahead and copy this skill. Now we're going to shift gears and create a new skill for brand guidelines that we'll use alongside this skill to create a compelling data-driven PowerPoint presentation. So let's go ahead and start with a new chat and we're going to ask Claude to create a brand guideline skill from files that we upload. The first thing I'm going to do is upload a file with my brand guidelines as well as some logos to be used in the presentation. Before we go ahead and create this skill, let me just show you what these brand guidelines look like. I've got a color palette, supporting colors, typography. Claude knows how to design things, but where skills really shine are where you can tell Claude exactly how you want things done for your company. logos, colors, fonts, great example. Now let's go ahead and create a skill from these files that we can apply to future presentations and documents. What we're going to see here is the skill creator skill in action again. We're leveraging the existing tooling and skills that we have to use best practices as well as the guideline and logos to make a skill that is repeatable and portable. We're going to analyze other existing skills to see what patterns they use and make sure that this new skill we're creating can complement them. And this is extremely valuable since we're going to be using this with PowerPoint presentations. Now that we have a good idea of what needs to be done, let's run that init_skill Python script that we saw before. This will create the underlying skill, and now we can start adding our assets to the skill's assets folder. We're going to start to see colors populate, accent colors, fonts, typography. And in a bit, we'll have a skill that we can start adding to all future conversations when there's design that we need done. Our logos are being pulled in, Word documents and PDFs are specified, and presentation layouts are the way that we want them to be. The skill creator has finished running. And here we have a SKILL.md file that's been created, following best practices with a name and a description, as well as underlying folders with the necessary data and logos that we need. There's one more step we need to do to make sure that this gets added to future conversations. In order to make sure this is saved to subsequent conversations, let's go ahead and copy this skill. Once this is done, we should see this skill in the list of skills that we've created. Now that we've updated our skill to move from CSVs to BigQuery, and created a new skill for our brand guidelines, let's combine that to build a workflow alongside the built-in PowerPoint presentation skill to first analyze our data and then generate a presentation. So we're going to first analyze our marketing data for a different week in BigQuery to see how each channel is doing. And then based on that data, generate a presentation with our brand guidelines. Let's see what this looks like. First, we're going to go ahead and read the relevant skill files. This includes our marketing campaign analysis and will include our BigQuery guidelines as well. We're going to go ahead and make sure we have the correct PowerPoint presentation skill as well as our brand skill for styling. Inside of the underlying PowerPoint presentation skill, there's additional documentation for presentation creation. First, we're going to go ahead and start with BigQuery. We're going to query what's necessary. We can take a look and see the underlying SQL that's being written and like we saw before, that date range that we're looking for. Now that we have the data, we're going to use these metrics to go ahead and generate a PowerPoint presentation. We're going to do so with the styling that we've advised in our brand style and turn this into a PowerPoint presentation. can see here the underlying CSS and HTML being written for our slides. And then we're going to lean into the built-in skill for creating the underlying presentation. Now that we've got the right HTML files, let's go ahead and create our presentation. Here we're using the native PowerPoint skill and writing the necessary code to create the presentation. We can see here even when there are particular issues, the model will go back edit anything necessary and lean on the exact workflow, not only for running code necessary, but validating what needs to be done. This ability that the model has to backtrack and follow particular patterns allows for us to create presentations that don't come with built-in issues that we need to immediately then correct. So we're seeing that Claude's done its verification, the slides look great. Now it's going to go ahead and generate that underlying PowerPoint presentation, which I can open up in Google Drive and use as Google Slides, or I can download directly. We can see here, I've got some really nice looking slides with the colors, fonts, logos, and everything that I want for my particular company. We have our efficiency analysis, funnel analysis, and the executive summary that highlights what needs review and what's doing quite well. I can download this presentation, I can continue to build off of it, and again, open it up in Google Drive to share with teammates. I can continue prompting and working with this presentation. But what we're seeing here is an underlying PowerPoint presentation created from a built-in skill, combined with two skills that we've made alongside an MCP server pulling in data from BigQuery. In the next lesson, we'll explore some of the best practices around creating skills and take a look at two other custom skills that we create and see if we're following the best practices.

DeepLearning.AI

Transcript We'll now take a closer look at how skills are structured and best practices for creating skills. Then we'll apply what you learn to two examples. One to create practice questions based on lecture notes, and another to analyze the characteristics of time series data. Let's go. In this lesson, we're going to focus a bit on the structure of a skill, some of the best practices associated with it. and then we're going to take a look at two skills that we make and see how they fare when run through the skill creator to see how they perform against some of the best practices. To review, every skill that we make has required SKILL.md file with some YAML Frontmatter that requires a name and a description. In the underlying SKILL.md, we have the content that goes in our skill, and then any references to scripts or any additional text files, assets necessary that are loaded only when necessary. As we take a look at some of the best practices for names and descriptions, you can imagine this is mission critical. Your name and description are not only how Claude can analyze what your skill does, but also detect when to use that particular skill. So with the name, there's a maximum of characters, same with the description. We mentioned briefly, the name has to contain lowercase letters, numbers and hyphens, and in general, stick with the verb plus ing form the name of your skill. For the description, you want to describe not only what it does, but also when to use it. And if there are specific keywords that lead to agents triggering this skill, make sure to lean into those. In addition to the required fields that you have, the agent skills specification allows for optional fields. This could be the license, compatibility, and arbitrary key-value pairs in your metadata. What's important to note here is that while there is a standard on agent skills, there are some skills that you might come across, some built by Anthropic, some others, that don't follow this specification to a T. The skills are in active development, as is the specification for skills as we work across many different model providers and many different agent tooling ecosystems. As we start to move past the YAML Frontmatter and into the underlying body of the skill, there are no underlying restrictions that we have for the format of our skill. However, when you think about building predictable workflows, you want to make sure you have step-by-step instructions. As we saw in other skills, especially the skill creator skill, it's important to specify edge cases, step-by-step instructions, and if there's a reason for a step to be skipped, be very clear why that is. In general, keeping this to under 500 lines is best practice, because we can always reference external files, assets, scripts, when necessary. In general, being clear and concise is valuable, and using forward slashes is mission critical even when on Windows. It's important to make sure the skill works across many different environments. When you think about creating skills, you want to think a little bit about how much freedom you want to give to that skill. Should we allow for general approaches and general directions, or should we be focusing on a specific sequence? You can imagine for following best practices, we might want a low degree of freedom, but for more creative outputs, multiple colors, multiple styles, multiple fonts, we can allow for that high degree of freedom. As we start to think about more complex workflows with multiple skills, breaking things down into sequential steps is always more valuable than having one very, very large skill that tries to do it all. These systems can handle 100+ skills. It's important to make sure that they're named appropriately, not confusing, and can be followed with a predictable pattern. In the specification, there's room for optional directories. And as we've seen with quite a few different skills, there are subfolders for scripts, references, and assets. Your scripts include any kind of code that needs to be read and executed. You also want to make sure you have error handling and clear documentation. Our references contain additional documentation or reference files. And in general, it's often valuable to instruct the skill to read the entire reference file if it happens to be quite long. Finally, we have underlying assets. These could include templates for output, images, logos, data files, schemas, and so on. It's important to note that these directories, scripts, references, and assets are following the standard of agent skills. But you might come across quite a few different skills that don't necessarily follow that particular standard yet. The standard is rapidly evolving and skills are also rapidly evolving. So going forward, we'd expect that skills created follow this standard. But you might come across some that have different folder names and different conventions. Now that we have a good sense of best practices, optional directories, and how to write production grade skills, let's take a look at two examples of skills that we've created, step through them, and then run them through the skill-creator to analyze for best practices and talk about evaluating these skills to make sure we're ready for production. So I'm in VS Code now. And here we have two custom skills that we're going to dive into. The first one is a generating practice questions skill. If we take a look at this skill, we can see that the description is for generating educational practice questions from lecture notes to test understanding. You can imagine you're a teacher or instructor, you want to provide a particular format for input and output. and you want to generate comprehensive questions to test understanding. Let's step through this skill. To start, we have supported formats for input. We specify what particular libraries to use, and we specify what text to extract. We then follow with our question structure. Again, we want to be very specific, so we're specifying the exact order that we want these questions generated in. Starting with True/False, working all the way towards realistic applications. For each of these questions, we have sub guidelines below. We can see here that this skill is not more than 500 lines of code. But if it needed to grow larger and larger, we can always include underlying files to reference to if necessary. As we take a look at some of these examples, for true and false, even coding questions and so on. We can see here, we're being very explicit with the scope and the structure and the required output for these particular questions. As we dive deeper into that output format, We specify that it depends on the user request. And instead of giving direct examples of every single kind of output, we're actually referencing templates inside of our assets folder. If we're dealing with LaTeX or we're dealing with Markdown, we specify exactly how we want that to look like. For example, with Markdown, here's how true and false might look like. With LaTeX, here is how our true and false and examples might look like as we go through. If you find yourself needing a particular kind of output format, instead of putting that all in the SKILL.md, reference it in an external asset or file. Remember that these files, these templates are only being loaded when necessary. So we can be extremely efficient with our tokens and context window. by only loading the particular file in the data format that we need. If there are external resources that we need, domain-specific examples, we can link to that as well, like we do in the references folder here. We're leaning into that concept of progressive disclosure by only loading what's absolutely necessary and referencing external files only when we need. The second skill we're going to look at is a skill for analyzing time series data. We're going to provide a CSV and we want to understand the characteristics before forecasting quite a few different things. What's important to note here is that as we go through this particular skill, there is a very particular deterministic workflow that we want to have. We're making use of a few different Python scripts to perform that particular action. To start, we have a Python script for visualizing the data that we're working with. Plotting the time series, a histogram, rolling stats, box plots, and quite a few more. For working with autocorrelation, we also have plots as well that we can draw. Similarly with decomposition. As we take a look at our diagnose.py, we have underlying functionality for analyzing the data that we're working with. While there are quite a few functions here, I want to draw your attention to what we do at the end when we run our diagnostics. We make use of these functions to analyze data quality, distribution, stationary tests, seasonality, trend, autocorrelation, and finally, end with a transform recommendation. What we have here is a predictable workflow that we want to run each time in a particular order. So let's go back and look at our skill to see exactly how that's done. First we're going to start with the format for our input. We're going to be very explicit for what we should be looking for, the names of the columns and the particular data types. Next we're going to move on to one of the most important parts of this skill, the workflow. Notice here, we're being extremely explicit with the steps that we have, telling our particular skill and Claude to run this exact script when we begin our diagnostics. We then have the option for generating the plots necessary and reporting this data to the user. taking this data, finding what's in the summary.txt and presenting the relevant plots. We can also see here for answering some of these questions that we might need, we have an interpretation.md file for guidance. As we take a look at some of the script options, we can add additional flags if necessary. And as we start to think about what's being output, we can specify exactly the tree of files, text files, images, and so on that we output. We want to be extremely predictable with the data that's coming in the operations that we perform, and then finally the output. As always, if there are external references, we can make sure to list those here. And given that we have scripts that are dependent on Python libraries, we need to make sure that we highlight exactly what those dependencies are and make sure that they're installed so that these scripts run correctly. Now that we've taken a look at these two custom skills that we've created, let's see how they stand up when we run this through the skill creator skill and determine if we're following best practices. We could do this in a couple environments. We can go back to Claude desktop, but what I'd like to show you is how we can use Claude Code with skills. We're going to see this in much more depth in a future lesson. But right now, I'm going to open up Claude Code. I'm going to install the necessary skill in our case skill-creator. And then we're going to use two subagents in parallel to evaluate our analyzing time series and our generating practice question skills. This is a really helpful way to just start the evaluation process for how well we've done with writing these skills. So we're going to go ahead and hop into Claude Code. Unlike Claude AI, Claude Code does not come with the built-in skills that include skill creator. So we need to install those. And we're going to do that using a marketplace. So we're going to head over to our Marketplaces. We're going to add a marketplace for anthropic/skills. This is the repository that we saw earlier that contains two collections. First, document-skills. These include processing Excel files, PowerPoints, Word docs, and PDFs. And the other collection are the example-skills. These are some of the other ones that we saw including the skill creator skill. So let's install this in the project scope. Once we install that, We're going to see that we need to restart Claude Code. And we're also going to see that in our .claude, we have in our settings.json the enabledPlugins that includes these skills. So let's go ahead and restart Claude Code and see what skills we have. And we can do that using the /skills command. If we've done this correctly, we should see that we have our skill-creator skill right here as expected. Let's go ahead and make use of that skill. So we're going to ask Claude Code to use the skill-creator skill to evaluate how these skills have followed best practices. To do this a little bit faster, we're going to use subagents in parallel where each subagent is evaluating each of the custom skills that I have. In order to do this, we're going to be prompted to use that skill, skill-creator, which is great. It's working as expected. We're going to successfully load that skill, read the necessary files, and go ahead and dispatch our subagents to check for best practices. We can see here, it's found the correct skills, generating practice questions, analyzing time series. And let's launch our two agents to evaluate these skills against best practices that we have. Alright, let's see how we did. Well, not too bad. generating practice questions, nine out of ten. We could improve a bit on the conciseness. We've got some nice recommendations here. The good news is we did even better on analyzing time series. We can see some observations here and some excellent job across avoiding duplication, Frontmatter quality, and conciseness. A really nice way to evaluate your skills is to run them through this skill creator, which includes best practices out of the box. So we've run our skills through this skill creator to analyze for best practices in the underlying SKILL.md and associated files, but how can we make sure the skills are working as expected? Here's one example that we could build a harness around to think about writing a unit test for our skills, similarly to how we write unit tests for software. So to start with our generating practice questions, when we think about what the evaluation might look like, we would start with a couple different queries. Generating questions and saving it to a markdown file, to a LaTeX file, to a PDF. we can go ahead and make sure that we're passing in the correct files in the correct format. We can then make sure that our expected behavior is what we need. Using the correct libraries for PDF input, extracting the learning objectives as we specified, generating different kinds of questions and following guidelines for those. using the correct output structure, using the correct output templates that we saw in our assets folder, making sure in certain data formats like LaTeX that it's successfully compiling. And then finally, making sure that our questions are generated to the correct files and the right format. We also would want to make sure that we gather human feedback in this process and that we test this across all the different models that we're planning to use. For our second skill for analyzing time series, we make use of three different Python scripts. So we're going to make the assumption that we've already tested those Python scripts with traditional unit tests in software. Assuming that those scripts are doing what we want them to do, let's now test that everything is happening in the correct order with the appropriate inputs and outputs and expected behavior. The query you might have here is to analyze and generate plots for some time series data. we'd want to pass in some potential CSVs, make sure that the Python scripts that we showed for visualizing and diagnosing are run correct. More importantly, making sure that all the steps in the workflow are in the correct order. we're asking for plots, we want to make sure that that optional step is included. We then want to return a summary, interpret those findings, and finally, create a folder with all the required files in their right place. If you can remember, in the output, we had a very specific location for different files, different folders, and underlying assets. Similarly to our other skill, we want to get human feedback and test across the models that we use. In the next lesson, we're going to take these two skills and bring them into Jupyter notebooks and use the Claude messages API to run these skills using code execution tools to produce outputs programmatically.
